{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5z2qHxGs/QQZq8DK0pf0k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuvan3535-boop/NeuroPlay-A-Deep-Learning-Model-for-Subject-Independent-Emotion-Classification-from-EEG/blob/main/Emotion_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNZGOI3fJZ-c",
        "outputId": "a5e85c92-fdd0-43e1-ef6f-2cfd8167af46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting mne\n",
            "  Downloading mne-1.10.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.10.5)\n",
            "Downloading mne-1.10.2-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install the MNE library (it's not pre-installed on Colab)\n",
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suPPxVNbW6Sy",
        "outputId": "a18d08d1-f227-4090-876c-a34f00117126"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'12th tc.jpg'\n",
            "'1st sem result_merged.pdf'\n",
            " 20180406_134222.jpg\n",
            " 20180406_134227.jpg\n",
            " 2018-08-27-21-33-24-890.jpg\n",
            " 20190929_082857.jpg\n",
            " 20190929_082900.jpg\n",
            " 20190929_082928.jpg\n",
            " 20190929_083025.jpg\n",
            " 20190929_083033.jpg\n",
            " 20190929_083055.jpg\n",
            " 20190929_084145.jpg\n",
            " 20190929_095548.jpg\n",
            " 20200216_080218.jpg\n",
            " 20200216_083256.jpg\n",
            " 20200525_135525.jpg\n",
            " 20200612_112019.jpg\n",
            " 20200612_205837.jpg\n",
            " 20200612_210041.jpg\n",
            " 20200612_210050.jpg\n",
            " 20200612_210056.jpg\n",
            " 20200612_210100.jpg\n",
            " 20200612_210118.jpg\n",
            " 20200612_210126.jpg\n",
            " 20200612_210137.jpg\n",
            "'20200612_210147(0).jpg'\n",
            " 20200612_210150.jpg\n",
            "'20200612_210209(0).jpg'\n",
            " 20200612_210211.jpg\n",
            " 20200612_210252.jpg\n",
            " 20200612_210304.jpg\n",
            " 20200617_091009.jpg\n",
            " 2223P1240100039.pdf\n",
            " aadhaar_dataset.xlsx\n",
            "'Aadhar (1).pdf'\n",
            "'Aadhar (2).pdf'\n",
            " Aadhar.pdf\n",
            "'adhaar 200kb.jpg'\n",
            " adhaar.jpg\n",
            " batch5_report.pdf\n",
            "'BE results_merged (1).pdf'\n",
            "'BE results_merged.pdf'\n",
            " BhuvanRNayak_DSATM.pdf\n",
            "'BhuvanRNayak_resume (10).pdf'\n",
            "'BhuvanRNayak_Resume (1) (10).pdf'\n",
            "'BhuvanRNayak_Resume (1) (11).pdf'\n",
            "'BhuvanRNayak_Resume (1) (12).pdf'\n",
            "'BhuvanRNayak_Resume (1) (13).pdf'\n",
            "'BhuvanRNayak_Resume (1) (14).pdf'\n",
            "'BhuvanRNayak_Resume (1) (15).pdf'\n",
            "'BhuvanRNayak_Resume (1) (16).pdf'\n",
            "'BhuvanRNayak_Resume (1) (17).pdf'\n",
            "'BhuvanRNayak_resume (11).pdf'\n",
            "'BhuvanRNayak_Resume (1) (1).pdf'\n",
            "'BhuvanRNayak_resume (12).pdf'\n",
            "'BhuvanRNayak_Resume (1) (2).pdf'\n",
            "'BhuvanRNayak_resume (13).pdf'\n",
            "'BhuvanRNayak_Resume (1) (3).pdf'\n",
            "'BhuvanRNayak_resume (14).pdf'\n",
            "'BhuvanRNayak_Resume (1) (4).pdf'\n",
            "'BhuvanRNayak_resume (15).pdf'\n",
            "'BhuvanRNayak_Resume (1) (5).pdf'\n",
            "'BhuvanRNayak_resume (16).pdf'\n",
            "'BhuvanRNayak_Resume (1) (6).pdf'\n",
            "'BhuvanRNayak_resume (17).pdf'\n",
            "'BhuvanRNayak_Resume (1) (7).pdf'\n",
            "'BhuvanRNayak_resume (18).pdf'\n",
            "'BhuvanRNayak_Resume (1) (8).pdf'\n",
            "'BhuvanRNayak_resume (19).pdf'\n",
            "'BhuvanRNayak_Resume (1) (9).pdf'\n",
            "'BhuvanRNayak_resume (1).pdf'\n",
            "'BhuvanRNayak_Resume (1).pdf'\n",
            "'BhuvanRNayak_resume (20).pdf'\n",
            "'BhuvanRNayak_resume (21).pdf'\n",
            "'BhuvanRNayak_resume (22).pdf'\n",
            "'BhuvanRNayak_resume (23).pdf'\n",
            "'BhuvanRNayak_resume (24).pdf'\n",
            "'BhuvanRNayak_resume (25).pdf'\n",
            "'BhuvanRNayak_resume (26).pdf'\n",
            "'BhuvanRNayak_resume (27).pdf'\n",
            "'BhuvanRNayak_resume (28).pdf'\n",
            "'BhuvanRNayak_resume (29).pdf'\n",
            "'BhuvanRNayak_resume (2).pdf'\n",
            "'BhuvanRNayak_resume (30).pdf'\n",
            "'BhuvanRNayak_resume (3).pdf'\n",
            "'BhuvanRNayak_resume (4).pdf'\n",
            "'BhuvanRNayak_resume (5).pdf'\n",
            "'BhuvanRNayak_resume (6).pdf'\n",
            "'BhuvanRNayak_resume (7).pdf'\n",
            "'BhuvanRNayak_resume (8).pdf'\n",
            "'BhuvanRNayak_resume (9).pdf'\n",
            " BhuvanRNayak_resume.pdf\n",
            " BhuvanRNayak_T110100504_Income.pdf\n",
            "'BhuvanRNayak_T1101005_Income (1).pdf'\n",
            " BhuvanRNayak_T1101005_Income.pdf\n",
            "'BhuvanRNayak_TNS_resume (1).pdf'\n",
            " BhuvanRNayak_TNS_resume.pdf\n",
            " certificates\n",
            "'check my resume ATS score and tell if all the gra....gsheet'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Crefit_EDA.ipynb\n",
            " eda.pdf\n",
            " FB_IMG_1591706180987.jpg\n",
            " FB_IMG_1591706245822.jpg\n",
            "'GAMEEMO (1)'\n",
            "'Getting started.pdf'\n",
            " hatespeech.ipynb\n",
            "'i have another file called gameplays, which conta....gsheet'\n",
            " IMG_20200611_210810_0.png\n",
            " IMG-20200703-WA0008.jpg\n",
            " IMG-20200703-WA0009.jpg\n",
            " IMG-20200703-WA0022.jpg\n",
            " IMG_20200712_100856_0.jpg\n",
            " IMG-20200802-WA0009.jpg\n",
            " IMG-20220815-WA0002.jpg\n",
            " IMG_20250515_110211017.jpg\n",
            "'Income  Certificate (1).pdf'\n",
            "'Income  Certificate.pdf'\n",
            "'KEA order copy.pdf'\n",
            "'New folder (2)'\n",
            "'pic 100kb.jpg'\n",
            "'predicting mortality of hear failure.ipynb'\n",
            "'PUC & 10th  marks card_merged (1).pdf'\n",
            "'PUC & 10th  marks card_merged.pdf'\n",
            "'PUC marks card_merged.pdf'\n",
            "'PUC Study Certificate.pdf'\n",
            "'ray-nzrp-ayo – 27 Jan 2021.pdf'\n",
            " scanner_20210618_150238\n",
            " Screenshot_20200612-121258_Gallery.jpg\n",
            " selfpotrait.jpg\n",
            "'Untitled presentation.gslides'\n",
            " Video_20191005130953535_by_videoshow.mp4\n",
            " Video_20191006085946788_by_videoshow.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "# --- 1. DEFINE CONSTANTS ---\n",
        "SAMPLING_RATE = 128\n",
        "CHANNEL_NAMES = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
        "LABEL_MAP = { 'G1': 0, 'G2': 1, 'G3': 2, 'G4': 3 }\n",
        "LABEL_NAMES = {0: 'Boring', 1: 'Calm', 2: 'Horror', 3: 'Funny'}\n",
        "\n",
        "EPOCH_DURATION_SEC = 3\n",
        "N_SAMPLES_PER_EPOCH = int(EPOCH_DURATION_SEC * SAMPLING_RATE) # This will be 384\n",
        "\n",
        "# --- Lists to hold all data from ALL subjects ---\n",
        "all_epochs_list = []\n",
        "all_labels_list = []\n",
        "all_groups_list = []\n",
        "\n",
        "# --- 2. FIND ALL SUBJECT FOLDERS (Robust Method) ---\n",
        "# This is the path to your GAMEEMO folder\n",
        "base_data_path = r'/content/drive/MyDrive/GAMEEMO (1)'\n",
        "\n",
        "subject_folders = []\n",
        "\n",
        "# Use os.listdir() to avoid issues with special characters in 'glob'\n",
        "try:\n",
        "    all_items_in_dir = os.listdir(base_data_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: The path {base_data_path} was not found.\")\n",
        "    print(\"Please double-check your base_data_path variable.\")\n",
        "    all_items_in_dir = []\n",
        "\n",
        "for item_name in all_items_in_dir:\n",
        "    # Check if it's a folder, starts with '(', and ends with ')'\n",
        "    full_path = os.path.join(base_data_path, item_name)\n",
        "    if (os.path.isdir(full_path) and\n",
        "        item_name.startswith('(') and\n",
        "        item_name.endswith(')')):\n",
        "\n",
        "        subject_folders.append(full_path)\n",
        "\n",
        "subject_folders.sort() # Sorts them (S01), (S02), ...\n",
        "\n",
        "print(f\"Found {len(subject_folders)} subjects.\")\n",
        "print(f\"Each epoch will have {N_SAMPLES_PER_EPOCH} timesteps.\")\n",
        "\n",
        "# --- 3. OUTER LOOP: Iterate through each subject ---\n",
        "for subject_folder_path in subject_folders:\n",
        "\n",
        "    # --- This is the new, safer way to get the ID ---\n",
        "    folder_name = os.path.basename(subject_folder_path) # Gets '(S01)'\n",
        "    subject_id = folder_name.strip('()')                # Gets 'S01'\n",
        "    # --- End new part ---\n",
        "\n",
        "    subject_group_id = int(subject_id[1:])\n",
        "\n",
        "    print(f\"\\n--- Processing Subject: {subject_id} ---\")\n",
        "\n",
        "    data_folder_path = os.path.join(subject_folder_path, 'Preprocessed EEG Data', '.csv format')\n",
        "    file_search_pattern = os.path.join(data_folder_path, f'{subject_id}G*AllChannels.csv')\n",
        "    subject_files = glob.glob(file_search_pattern)\n",
        "    subject_files.sort()\n",
        "\n",
        "    if not subject_files:\n",
        "        print(f\"Warning: No files found for {subject_id} at {data_folder_path}\")\n",
        "        continue\n",
        "\n",
        "    # --- 4. INNER LOOP: Process each game file (G1-G4) for this subject ---\n",
        "    for csv_file_path in subject_files:\n",
        "        file_name = os.path.basename(csv_file_path)\n",
        "        game_key = file_name.split('AllChannels.csv')[0][3:]\n",
        "\n",
        "        if game_key not in LABEL_MAP:\n",
        "            continue\n",
        "\n",
        "        label = LABEL_MAP[game_key]\n",
        "\n",
        "        # 1. Load Data\n",
        "        eeg_df = pd.read_csv(csv_file_path)\n",
        "        eeg_df = eeg_df[CHANNEL_NAMES]\n",
        "\n",
        "        # 2. Convert to MNE\n",
        "        if eeg_df['AF3'].mean() < 0.1:\n",
        "             eeg_data_numpy = eeg_df.values.T * 1e6\n",
        "        else:\n",
        "             eeg_data_numpy = eeg_df.values.T\n",
        "\n",
        "        # 3. Create MNE Object\n",
        "        ch_types = ['eeg'] * len(CHANNEL_NAMES)\n",
        "        info = mne.create_info(ch_names=CHANNEL_NAMES, sfreq=SAMPLING_RATE, ch_types=ch_types)\n",
        "        info.set_montage('standard_1020')\n",
        "        raw = mne.io.RawArray(eeg_data_numpy, info, verbose=False)\n",
        "\n",
        "        # 4. Epoching\n",
        "        epochs = mne.make_fixed_length_epochs(raw, duration=EPOCH_DURATION_SEC, overlap=1.0, preload=True, verbose=False)\n",
        "\n",
        "        # 5. GET EPOCH DATA\n",
        "        epoch_data = epochs.get_data() # (n_epochs, n_channels, n_samples)\n",
        "        n_epochs = epoch_data.shape[0]\n",
        "\n",
        "        # 6. Append to our MASTER lists\n",
        "        all_epochs_list.append(epoch_data)\n",
        "        all_labels_list.extend([label] * n_epochs)\n",
        "        all_groups_list.extend([subject_group_id] * n_epochs)\n",
        "\n",
        "# --- 6. FINAL STEP: Combine all data ---\n",
        "if not all_epochs_list:\n",
        "    print(\"\\n--- No data was processed. Check your paths and folder structure. ---\")\n",
        "else:\n",
        "    X = np.concatenate(all_epochs_list)\n",
        "    y = np.array(all_labels_list)\n",
        "    groups = np.array(all_groups_list)\n",
        "\n",
        "    # 7. CRITICAL: Reshape data for the 1D-CNN\n",
        "    X = np.transpose(X, (0, 2, 1)) # -> Shape (samples, timesteps, channels)\n",
        "\n",
        "    print(f\"\\n--- ALL PROCESSING COMPLETE ---\")\n",
        "    print(f\"Feature matrix 'X' shape: {X.shape}\")\n",
        "    print(f\"Label vector 'y' shape: {y.shape}\")\n",
        "    print(f\"Groups vector 'groups' shape: {groups.shape}\")\n",
        "    print(f\"Total subjects processed: {len(np.unique(groups))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FakUMRJJUx44",
        "outputId": "1400bc10-f220-47a2-9f6a-7b3539f55baf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 subjects.\n",
            "Each epoch will have 384 timesteps.\n",
            "\n",
            "--- Processing Subject: S01 ---\n",
            "\n",
            "--- Processing Subject: S02 ---\n",
            "\n",
            "--- Processing Subject: S03 ---\n",
            "\n",
            "--- Processing Subject: S04 ---\n",
            "\n",
            "--- Processing Subject: S05 ---\n",
            "\n",
            "--- Processing Subject: S06 ---\n",
            "\n",
            "--- Processing Subject: S07 ---\n",
            "\n",
            "--- Processing Subject: S08 ---\n",
            "\n",
            "--- Processing Subject: S09 ---\n",
            "\n",
            "--- Processing Subject: S10 ---\n",
            "\n",
            "--- Processing Subject: S11 ---\n",
            "\n",
            "--- Processing Subject: S12 ---\n",
            "\n",
            "--- Processing Subject: S13 ---\n",
            "\n",
            "--- Processing Subject: S14 ---\n",
            "\n",
            "--- Processing Subject: S15 ---\n",
            "\n",
            "--- Processing Subject: S16 ---\n",
            "\n",
            "--- Processing Subject: S17 ---\n",
            "\n",
            "--- Processing Subject: S18 ---\n",
            "\n",
            "--- Processing Subject: S19 ---\n",
            "\n",
            "--- Processing Subject: S20 ---\n",
            "\n",
            "--- Processing Subject: S21 ---\n",
            "\n",
            "--- Processing Subject: S22 ---\n",
            "\n",
            "--- Processing Subject: S23 ---\n",
            "\n",
            "--- Processing Subject: S24 ---\n",
            "\n",
            "--- Processing Subject: S25 ---\n",
            "\n",
            "--- Processing Subject: S26 ---\n",
            "\n",
            "--- Processing Subject: S27 ---\n",
            "\n",
            "--- Processing Subject: S28 ---\n",
            "\n",
            "--- ALL PROCESSING COMPLETE ---\n",
            "Feature matrix 'X' shape: (16576, 384, 14)\n",
            "Label vector 'y' shape: (16576,)\n",
            "Groups vector 'groups' shape: (16576,)\n",
            "Total subjects processed: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# --- 1. Define the 1D-CNN Model Architecture ---\n",
        "# We create a function so we can build a fresh, new model for each fold\n",
        "def build_1d_cnn_model(input_shape=(N_SAMPLES_PER_EPOCH, len(CHANNEL_NAMES))):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input shape: (384, 14)\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output layer: 4 classes, softmax for probabilities\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy', # Use this because our y is 0, 1, 2, 3\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 2. Set up the Cross-Validation Loop ---\n",
        "logo = LeaveOneGroupOut()\n",
        "n_splits = logo.get_n_splits(X, y, groups)\n",
        "\n",
        "all_y_test = []\n",
        "all_y_pred_classes = []\n",
        "fold_accuracies = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# --- 3. Run the Cross-Validation Loop ---\n",
        "for fold, (train_index, test_index) in enumerate(logo.split(X, y, groups)):\n",
        "\n",
        "    test_subject_id = np.unique(groups[test_index])[0]\n",
        "    print(f\"\\n--- FOLD {fold+1}/{n_splits} | TESTING on Subject {test_subject_id} ---\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # --- 4. CRITICAL: Normalization ---\n",
        "    # We must normalize the data. We fit the scaler ONLY on the training data\n",
        "    # to prevent any data leakage from the test subject.\n",
        "    # We must reshape 3D -> 2D to scale, then 2D -> 3D back.\n",
        "\n",
        "    # Reshape (n_epochs, 384, 14) -> (n_epochs * 384, 14)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
        "    scaler.fit(X_train_2d)\n",
        "\n",
        "    # Transform\n",
        "    X_train_norm_2d = scaler.transform(X_train_2d)\n",
        "    X_test_norm_2d = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n",
        "\n",
        "    # Reshape back to 3D\n",
        "    X_train = X_train_norm_2d.reshape(X_train.shape)\n",
        "    X_test = X_test_norm_2d.reshape(X_test.shape)\n",
        "\n",
        "    print(f\"Data normalized. Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
        "\n",
        "    # 5. Build and Train the Model\n",
        "    model = build_1d_cnn_model()\n",
        "\n",
        "    # We'll use 10% of our *training* data as a validation set\n",
        "    # to monitor for overfitting during training.\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, # 20 epochs is a good start\n",
        "        batch_size=32,\n",
        "        validation_split=0.1, # Use 10% of train data for validation\n",
        "        verbose=1 # Set to 0 if you want less text\n",
        "    )\n",
        "\n",
        "    # 6. Evaluate on the held-out subject\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Get class predictions\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Store results\n",
        "    fold_accuracies.append(accuracy)\n",
        "    all_y_test.extend(y_test)\n",
        "    all_y_pred_classes.extend(y_pred)\n",
        "\n",
        "    print(f\"Accuracy on Subject {test_subject_id}: {accuracy * 100:.2f}%\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- Total DL Training Time: {(end_time - start_time)/60:.2f} minutes ---\")\n",
        "\n",
        "# --- 7. EVALUATE YOUR FINAL MODEL ---\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"\\n\\nModel Accuracy (Mean): {mean_accuracy * 100:.2f}%\")\n",
        "print(f\"Model Accuracy (Std Dev): {np.std(fold_accuracies) * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nOverall Classification Report:\")\n",
        "class_names = [LABEL_NAMES[i] for i in sorted(LABEL_MAP.values())]\n",
        "print(classification_report(all_y_test, all_y_pred_classes, target_names=class_names))\n",
        "\n",
        "print(\"\\nOverall Confusion Matrix:\")\n",
        "cm = confusion_matrix(all_y_test, all_y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Subject-Independent 1D-CNN Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0MGy9JYWYyC3",
        "outputId": "64ef828d-b99d-4508-d63d-d7a6878a44ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- FOLD 1/28 | TESTING on Subject 1 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.3245 - loss: 1.6541 - val_accuracy: 0.3621 - val_loss: 1.3350\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4954 - loss: 1.0890 - val_accuracy: 0.3740 - val_loss: 1.3019\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 0.8793 - val_accuracy: 0.4121 - val_loss: 1.2680\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6677 - loss: 0.7723 - val_accuracy: 0.4916 - val_loss: 1.1335\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.6619 - val_accuracy: 0.5610 - val_loss: 1.0330\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.5791 - val_accuracy: 0.5622 - val_loss: 1.0682\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 0.5023 - val_accuracy: 0.6235 - val_loss: 0.8936\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.4471 - val_accuracy: 0.6623 - val_loss: 0.8198\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3962 - val_accuracy: 0.7179 - val_loss: 0.6946\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.3669 - val_accuracy: 0.7123 - val_loss: 0.6927\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.3272 - val_accuracy: 0.7598 - val_loss: 0.5981\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.2889 - val_accuracy: 0.7661 - val_loss: 0.5774\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2877 - val_accuracy: 0.8130 - val_loss: 0.5250\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.2833 - val_accuracy: 0.8437 - val_loss: 0.4547\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9080 - loss: 0.2383 - val_accuracy: 0.8130 - val_loss: 0.5267\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2283 - val_accuracy: 0.8324 - val_loss: 0.4572\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2100 - val_accuracy: 0.8962 - val_loss: 0.3460\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1974 - val_accuracy: 0.8086 - val_loss: 0.5125\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2006 - val_accuracy: 0.8386 - val_loss: 0.4247\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2170 - val_accuracy: 0.9012 - val_loss: 0.2941\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 1: 95.95%\n",
            "\n",
            "--- FOLD 2/28 | TESTING on Subject 2 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3154 - loss: 1.6350 - val_accuracy: 0.3421 - val_loss: 1.3529\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4889 - loss: 1.1092 - val_accuracy: 0.3796 - val_loss: 1.3219\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6024 - loss: 0.9148 - val_accuracy: 0.4290 - val_loss: 1.2504\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6762 - loss: 0.7619 - val_accuracy: 0.4853 - val_loss: 1.1363\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7234 - loss: 0.6692 - val_accuracy: 0.5816 - val_loss: 1.0167\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.5717 - val_accuracy: 0.5860 - val_loss: 0.9581\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.5072 - val_accuracy: 0.6398 - val_loss: 0.8712\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8214 - loss: 0.4475 - val_accuracy: 0.6836 - val_loss: 0.7681\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8377 - loss: 0.3924 - val_accuracy: 0.6610 - val_loss: 0.8528\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.3729 - val_accuracy: 0.6979 - val_loss: 0.7970\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3519 - val_accuracy: 0.7530 - val_loss: 0.6441\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.3151 - val_accuracy: 0.7830 - val_loss: 0.5717\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2867 - val_accuracy: 0.8105 - val_loss: 0.4903\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2544 - val_accuracy: 0.8643 - val_loss: 0.4011\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2460 - val_accuracy: 0.8386 - val_loss: 0.4524\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9091 - loss: 0.2275 - val_accuracy: 0.8361 - val_loss: 0.4621\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2177 - val_accuracy: 0.8774 - val_loss: 0.3448\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2144 - val_accuracy: 0.8962 - val_loss: 0.3285\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2054 - val_accuracy: 0.9068 - val_loss: 0.3014\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 0.2022 - val_accuracy: 0.9112 - val_loss: 0.2460\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 2: 94.09%\n",
            "\n",
            "--- FOLD 3/28 | TESTING on Subject 3 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3130 - loss: 1.7128 - val_accuracy: 0.3627 - val_loss: 1.3723\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4806 - loss: 1.1277 - val_accuracy: 0.3909 - val_loss: 1.2624\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 0.9257 - val_accuracy: 0.4165 - val_loss: 1.2840\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.8139 - val_accuracy: 0.4959 - val_loss: 1.1708\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.6965 - val_accuracy: 0.5291 - val_loss: 1.1169\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.5968 - val_accuracy: 0.5872 - val_loss: 0.9513\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.5103 - val_accuracy: 0.5804 - val_loss: 1.0868\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4640 - val_accuracy: 0.7036 - val_loss: 0.7654\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 0.3989 - val_accuracy: 0.6742 - val_loss: 0.8261\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3615 - val_accuracy: 0.7611 - val_loss: 0.6175\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3115 - val_accuracy: 0.7999 - val_loss: 0.5620\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.2930 - val_accuracy: 0.8086 - val_loss: 0.5213\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.2818 - val_accuracy: 0.8274 - val_loss: 0.4738\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2553 - val_accuracy: 0.8174 - val_loss: 0.5077\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2371 - val_accuracy: 0.8299 - val_loss: 0.4606\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2525 - val_accuracy: 0.8674 - val_loss: 0.3808\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2099 - val_accuracy: 0.8537 - val_loss: 0.4154\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.1954 - val_accuracy: 0.8762 - val_loss: 0.3523\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2040 - val_accuracy: 0.9031 - val_loss: 0.2823\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.1906 - val_accuracy: 0.9174 - val_loss: 0.2735\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 3: 99.32%\n",
            "\n",
            "--- FOLD 4/28 | TESTING on Subject 4 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3067 - loss: 1.7177 - val_accuracy: 0.3233 - val_loss: 1.3818\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4821 - loss: 1.1332 - val_accuracy: 0.4040 - val_loss: 1.2700\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.9105 - val_accuracy: 0.4459 - val_loss: 1.2311\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.7693 - val_accuracy: 0.5059 - val_loss: 1.0949\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7312 - loss: 0.6508 - val_accuracy: 0.5622 - val_loss: 1.0412\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.5697 - val_accuracy: 0.5629 - val_loss: 1.0560\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.5195 - val_accuracy: 0.6048 - val_loss: 0.9770\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.4361 - val_accuracy: 0.6948 - val_loss: 0.7679\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3914 - val_accuracy: 0.7154 - val_loss: 0.6924\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3530 - val_accuracy: 0.7467 - val_loss: 0.6376\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3226 - val_accuracy: 0.7336 - val_loss: 0.6779\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2899 - val_accuracy: 0.8049 - val_loss: 0.5282\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.3015 - val_accuracy: 0.8049 - val_loss: 0.5084\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.2418 - val_accuracy: 0.8380 - val_loss: 0.4419\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2285 - val_accuracy: 0.8299 - val_loss: 0.4597\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2419 - val_accuracy: 0.8543 - val_loss: 0.4044\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2170 - val_accuracy: 0.8612 - val_loss: 0.4071\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2121 - val_accuracy: 0.8649 - val_loss: 0.3657\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.2028 - val_accuracy: 0.8674 - val_loss: 0.3654\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.1940 - val_accuracy: 0.8937 - val_loss: 0.3426\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 4: 87.16%\n",
            "\n",
            "--- FOLD 5/28 | TESTING on Subject 5 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.3130 - loss: 1.6009 - val_accuracy: 0.3271 - val_loss: 1.3230\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4890 - loss: 1.1130 - val_accuracy: 0.4228 - val_loss: 1.2897\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6037 - loss: 0.8990 - val_accuracy: 0.4428 - val_loss: 1.2310\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.7640 - val_accuracy: 0.5128 - val_loss: 1.0965\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.6531 - val_accuracy: 0.5729 - val_loss: 1.0393\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7680 - loss: 0.5572 - val_accuracy: 0.6029 - val_loss: 0.9310\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.5144 - val_accuracy: 0.6535 - val_loss: 0.8497\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4296 - val_accuracy: 0.6141 - val_loss: 0.9568\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.3904 - val_accuracy: 0.7523 - val_loss: 0.6499\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.3375 - val_accuracy: 0.7405 - val_loss: 0.6458\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.3095 - val_accuracy: 0.7517 - val_loss: 0.6166\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.2971 - val_accuracy: 0.7999 - val_loss: 0.5354\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2821 - val_accuracy: 0.8430 - val_loss: 0.4595\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.2558 - val_accuracy: 0.8224 - val_loss: 0.4690\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2220 - val_accuracy: 0.8386 - val_loss: 0.4556\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2105 - val_accuracy: 0.8518 - val_loss: 0.4371\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2056 - val_accuracy: 0.8705 - val_loss: 0.3783\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1980 - val_accuracy: 0.8618 - val_loss: 0.3944\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2070 - val_accuracy: 0.8705 - val_loss: 0.3553\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9349 - loss: 0.1783 - val_accuracy: 0.8168 - val_loss: 0.5411\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 5: 91.72%\n",
            "\n",
            "--- FOLD 6/28 | TESTING on Subject 6 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3249 - loss: 1.6938 - val_accuracy: 0.3390 - val_loss: 1.3646\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 1.0756 - val_accuracy: 0.3884 - val_loss: 1.3345\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 0.9131 - val_accuracy: 0.3884 - val_loss: 1.2770\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6426 - loss: 0.8151 - val_accuracy: 0.4728 - val_loss: 1.1872\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.7005 - val_accuracy: 0.5122 - val_loss: 1.1080\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7395 - loss: 0.6126 - val_accuracy: 0.5453 - val_loss: 1.0494\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.5384 - val_accuracy: 0.6210 - val_loss: 0.8763\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4763 - val_accuracy: 0.6629 - val_loss: 0.8362\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8340 - loss: 0.4071 - val_accuracy: 0.6954 - val_loss: 0.7492\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.3724 - val_accuracy: 0.7098 - val_loss: 0.7049\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3619 - val_accuracy: 0.7323 - val_loss: 0.6784\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8728 - loss: 0.3323 - val_accuracy: 0.7086 - val_loss: 0.7735\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3005 - val_accuracy: 0.6698 - val_loss: 0.8847\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2626 - val_accuracy: 0.7886 - val_loss: 0.5316\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.2660 - val_accuracy: 0.7867 - val_loss: 0.5376\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.2453 - val_accuracy: 0.8449 - val_loss: 0.4160\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.2203 - val_accuracy: 0.8568 - val_loss: 0.3983\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2338 - val_accuracy: 0.8612 - val_loss: 0.3671\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.1951 - val_accuracy: 0.8680 - val_loss: 0.3507\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.1945 - val_accuracy: 0.8724 - val_loss: 0.3439\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 6: 94.59%\n",
            "\n",
            "--- FOLD 7/28 | TESTING on Subject 7 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3344 - loss: 1.6832 - val_accuracy: 0.3646 - val_loss: 1.3274\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5148 - loss: 1.0518 - val_accuracy: 0.3990 - val_loss: 1.2717\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 0.8853 - val_accuracy: 0.4371 - val_loss: 1.1958\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.7720 - val_accuracy: 0.4984 - val_loss: 1.1366\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.6612 - val_accuracy: 0.5435 - val_loss: 1.0459\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7668 - loss: 0.5559 - val_accuracy: 0.6010 - val_loss: 0.9237\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.5063 - val_accuracy: 0.6448 - val_loss: 0.8633\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4657 - val_accuracy: 0.6717 - val_loss: 0.7989\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8393 - loss: 0.4038 - val_accuracy: 0.7173 - val_loss: 0.7022\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 0.3538 - val_accuracy: 0.6929 - val_loss: 0.7511\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3263 - val_accuracy: 0.7342 - val_loss: 0.6343\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.3087 - val_accuracy: 0.7830 - val_loss: 0.5466\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8940 - loss: 0.2708 - val_accuracy: 0.8099 - val_loss: 0.5175\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.2628 - val_accuracy: 0.8255 - val_loss: 0.5038\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2519 - val_accuracy: 0.8061 - val_loss: 0.5204\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.2418 - val_accuracy: 0.7317 - val_loss: 0.7791\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.2069 - val_accuracy: 0.8580 - val_loss: 0.4383\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.1981 - val_accuracy: 0.8799 - val_loss: 0.3388\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1889 - val_accuracy: 0.9043 - val_loss: 0.2906\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.1856 - val_accuracy: 0.9106 - val_loss: 0.2596\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 7: 95.10%\n",
            "\n",
            "--- FOLD 8/28 | TESTING on Subject 8 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.3390 - loss: 1.6690 - val_accuracy: 0.3640 - val_loss: 1.3013\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5279 - loss: 1.0548 - val_accuracy: 0.3709 - val_loss: 1.3158\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6182 - loss: 0.8738 - val_accuracy: 0.4384 - val_loss: 1.2254\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.7332 - val_accuracy: 0.4834 - val_loss: 1.1519\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.6189 - val_accuracy: 0.5272 - val_loss: 1.0706\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.5356 - val_accuracy: 0.5622 - val_loss: 1.0182\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4840 - val_accuracy: 0.6010 - val_loss: 0.9613\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4529 - val_accuracy: 0.6704 - val_loss: 0.7886\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3896 - val_accuracy: 0.6410 - val_loss: 0.8905\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.3554 - val_accuracy: 0.7186 - val_loss: 0.6879\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.3176 - val_accuracy: 0.7786 - val_loss: 0.5773\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.2965 - val_accuracy: 0.7892 - val_loss: 0.5625\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2919 - val_accuracy: 0.8361 - val_loss: 0.4756\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.2562 - val_accuracy: 0.8361 - val_loss: 0.4669\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2359 - val_accuracy: 0.8380 - val_loss: 0.4483\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2251 - val_accuracy: 0.8099 - val_loss: 0.5260\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2309 - val_accuracy: 0.8662 - val_loss: 0.3750\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.2106 - val_accuracy: 0.8743 - val_loss: 0.3671\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1992 - val_accuracy: 0.8249 - val_loss: 0.5139\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.1888 - val_accuracy: 0.8311 - val_loss: 0.5331\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 8: 94.59%\n",
            "\n",
            "--- FOLD 9/28 | TESTING on Subject 9 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3307 - loss: 1.6331 - val_accuracy: 0.3465 - val_loss: 1.3416\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5410 - loss: 1.0231 - val_accuracy: 0.4253 - val_loss: 1.2553\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6304 - loss: 0.8424 - val_accuracy: 0.4009 - val_loss: 1.2421\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6935 - loss: 0.7374 - val_accuracy: 0.4534 - val_loss: 1.2105\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7431 - loss: 0.6056 - val_accuracy: 0.5297 - val_loss: 1.0803\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.5452 - val_accuracy: 0.6066 - val_loss: 0.9400\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4767 - val_accuracy: 0.6166 - val_loss: 0.9196\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4335 - val_accuracy: 0.6704 - val_loss: 0.8254\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3903 - val_accuracy: 0.7004 - val_loss: 0.7421\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3575 - val_accuracy: 0.7398 - val_loss: 0.6943\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3208 - val_accuracy: 0.7705 - val_loss: 0.6232\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2944 - val_accuracy: 0.7667 - val_loss: 0.6127\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.2696 - val_accuracy: 0.7930 - val_loss: 0.5479\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9026 - loss: 0.2465 - val_accuracy: 0.8255 - val_loss: 0.4605\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.2460 - val_accuracy: 0.8430 - val_loss: 0.4397\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2296 - val_accuracy: 0.8430 - val_loss: 0.4476\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.2036 - val_accuracy: 0.8274 - val_loss: 0.4788\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.1906 - val_accuracy: 0.8749 - val_loss: 0.3985\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.1937 - val_accuracy: 0.8361 - val_loss: 0.4059\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9277 - loss: 0.1831 - val_accuracy: 0.8962 - val_loss: 0.3365\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 9: 89.36%\n",
            "\n",
            "--- FOLD 10/28 | TESTING on Subject 10 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3122 - loss: 1.7509 - val_accuracy: 0.3533 - val_loss: 1.3292\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5195 - loss: 1.0745 - val_accuracy: 0.3684 - val_loss: 1.3314\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6297 - loss: 0.8485 - val_accuracy: 0.4472 - val_loss: 1.2159\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6975 - loss: 0.7145 - val_accuracy: 0.4816 - val_loss: 1.1548\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.6114 - val_accuracy: 0.5378 - val_loss: 1.0299\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.5360 - val_accuracy: 0.5979 - val_loss: 0.9547\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.4572 - val_accuracy: 0.6498 - val_loss: 0.8440\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.4036 - val_accuracy: 0.6954 - val_loss: 0.7282\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3649 - val_accuracy: 0.6967 - val_loss: 0.7193\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.3442 - val_accuracy: 0.6811 - val_loss: 0.8244\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.2916 - val_accuracy: 0.7586 - val_loss: 0.6154\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.2899 - val_accuracy: 0.7874 - val_loss: 0.5517\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.2720 - val_accuracy: 0.7892 - val_loss: 0.5841\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2496 - val_accuracy: 0.8424 - val_loss: 0.4761\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2433 - val_accuracy: 0.8562 - val_loss: 0.4330\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.2295 - val_accuracy: 0.8674 - val_loss: 0.3646\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.1945 - val_accuracy: 0.9112 - val_loss: 0.2921\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.1908 - val_accuracy: 0.8755 - val_loss: 0.3607\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.1980 - val_accuracy: 0.9137 - val_loss: 0.2813\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.1722 - val_accuracy: 0.8924 - val_loss: 0.2966\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 10: 96.62%\n",
            "\n",
            "--- FOLD 11/28 | TESTING on Subject 11 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.3318 - loss: 1.6298 - val_accuracy: 0.3258 - val_loss: 1.3409\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5351 - loss: 1.0291 - val_accuracy: 0.4109 - val_loss: 1.2883\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 0.8553 - val_accuracy: 0.4396 - val_loss: 1.2154\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.7288 - val_accuracy: 0.5247 - val_loss: 1.0880\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7451 - loss: 0.6176 - val_accuracy: 0.5285 - val_loss: 1.1156\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 0.5517 - val_accuracy: 0.6191 - val_loss: 0.9465\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4907 - val_accuracy: 0.6504 - val_loss: 0.8791\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4218 - val_accuracy: 0.6873 - val_loss: 0.7824\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3939 - val_accuracy: 0.6867 - val_loss: 0.7826\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3583 - val_accuracy: 0.7467 - val_loss: 0.6774\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3339 - val_accuracy: 0.7674 - val_loss: 0.6101\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.2912 - val_accuracy: 0.7742 - val_loss: 0.5930\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2902 - val_accuracy: 0.8305 - val_loss: 0.4629\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.2522 - val_accuracy: 0.7780 - val_loss: 0.6261\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.2739 - val_accuracy: 0.8605 - val_loss: 0.4338\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2068 - val_accuracy: 0.8224 - val_loss: 0.4801\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2151 - val_accuracy: 0.8649 - val_loss: 0.3868\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9130 - loss: 0.2188 - val_accuracy: 0.8981 - val_loss: 0.3054\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2004 - val_accuracy: 0.8962 - val_loss: 0.3158\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.1809 - val_accuracy: 0.9250 - val_loss: 0.2539\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 11: 96.28%\n",
            "\n",
            "--- FOLD 12/28 | TESTING on Subject 12 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3255 - loss: 1.6795 - val_accuracy: 0.3139 - val_loss: 1.4012\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5233 - loss: 1.0448 - val_accuracy: 0.3402 - val_loss: 1.4287\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.8496 - val_accuracy: 0.3752 - val_loss: 1.4003\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6863 - loss: 0.7382 - val_accuracy: 0.4115 - val_loss: 1.4350\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.6402 - val_accuracy: 0.4909 - val_loss: 1.2587\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.5299 - val_accuracy: 0.5266 - val_loss: 1.3259\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4599 - val_accuracy: 0.5366 - val_loss: 1.3630\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4110 - val_accuracy: 0.5810 - val_loss: 1.2997\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.3476 - val_accuracy: 0.5766 - val_loss: 1.4325\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.3322 - val_accuracy: 0.6304 - val_loss: 1.1862\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.3222 - val_accuracy: 0.6635 - val_loss: 1.1893\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.2709 - val_accuracy: 0.6567 - val_loss: 1.2564\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.2623 - val_accuracy: 0.6892 - val_loss: 1.2082\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2349 - val_accuracy: 0.6767 - val_loss: 1.1513\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2420 - val_accuracy: 0.7248 - val_loss: 1.0310\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.2184 - val_accuracy: 0.7355 - val_loss: 1.1386\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.1948 - val_accuracy: 0.6998 - val_loss: 1.4858\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.1987 - val_accuracy: 0.7498 - val_loss: 1.0852\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.1819 - val_accuracy: 0.7467 - val_loss: 1.1255\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.1736 - val_accuracy: 0.7373 - val_loss: 1.2974\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 12: 51.69%\n",
            "\n",
            "--- FOLD 13/28 | TESTING on Subject 13 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3167 - loss: 1.6545 - val_accuracy: 0.3021 - val_loss: 1.4053\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5283 - loss: 1.0355 - val_accuracy: 0.3058 - val_loss: 1.4535\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6422 - loss: 0.8436 - val_accuracy: 0.3827 - val_loss: 1.3704\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7076 - loss: 0.6955 - val_accuracy: 0.4121 - val_loss: 1.3835\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.5543 - val_accuracy: 0.4434 - val_loss: 1.4499\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4911 - val_accuracy: 0.4484 - val_loss: 1.5162\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.4228 - val_accuracy: 0.5066 - val_loss: 1.4776\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3808 - val_accuracy: 0.5278 - val_loss: 1.6098\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3277 - val_accuracy: 0.5585 - val_loss: 1.5541\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.2889 - val_accuracy: 0.5785 - val_loss: 1.6196\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.2810 - val_accuracy: 0.5666 - val_loss: 1.4781\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.2619 - val_accuracy: 0.6304 - val_loss: 1.5770\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.2315 - val_accuracy: 0.6298 - val_loss: 1.5144\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.2354 - val_accuracy: 0.6454 - val_loss: 1.4980\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2057 - val_accuracy: 0.6617 - val_loss: 1.4411\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1958 - val_accuracy: 0.6460 - val_loss: 1.3860\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.1800 - val_accuracy: 0.6748 - val_loss: 1.8941\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.1839 - val_accuracy: 0.6585 - val_loss: 1.6694\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1505 - val_accuracy: 0.6898 - val_loss: 1.5045\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.1572 - val_accuracy: 0.6836 - val_loss: 1.5659\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 13: 26.86%\n",
            "\n",
            "--- FOLD 14/28 | TESTING on Subject 14 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3146 - loss: 1.6865 - val_accuracy: 0.3102 - val_loss: 1.3881\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5038 - loss: 1.0733 - val_accuracy: 0.3652 - val_loss: 1.3378\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 0.8691 - val_accuracy: 0.3984 - val_loss: 1.3922\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6772 - loss: 0.7562 - val_accuracy: 0.3977 - val_loss: 1.4137\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.6227 - val_accuracy: 0.4765 - val_loss: 1.3768\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.5153 - val_accuracy: 0.4759 - val_loss: 1.3034\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4459 - val_accuracy: 0.5397 - val_loss: 1.4953\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3945 - val_accuracy: 0.5604 - val_loss: 1.3403\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.3497 - val_accuracy: 0.5453 - val_loss: 1.3150\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8822 - loss: 0.3074 - val_accuracy: 0.5929 - val_loss: 1.3505\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.2793 - val_accuracy: 0.6016 - val_loss: 1.2364\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2469 - val_accuracy: 0.6098 - val_loss: 1.2464\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2305 - val_accuracy: 0.6266 - val_loss: 1.4010\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2217 - val_accuracy: 0.6298 - val_loss: 1.1567\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.1903 - val_accuracy: 0.6398 - val_loss: 1.2507\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.1806 - val_accuracy: 0.6535 - val_loss: 1.3625\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.1882 - val_accuracy: 0.6660 - val_loss: 1.1680\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1706 - val_accuracy: 0.6379 - val_loss: 1.7156\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.1599 - val_accuracy: 0.6642 - val_loss: 1.2701\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1507 - val_accuracy: 0.6848 - val_loss: 1.2125\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
            "Accuracy on Subject 14: 22.47%\n",
            "\n",
            "--- FOLD 15/28 | TESTING on Subject 15 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3209 - loss: 1.7361 - val_accuracy: 0.3458 - val_loss: 1.3536\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 1.1062 - val_accuracy: 0.3665 - val_loss: 1.3134\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 0.9126 - val_accuracy: 0.4346 - val_loss: 1.2314\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6779 - loss: 0.7622 - val_accuracy: 0.4809 - val_loss: 1.1385\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.6506 - val_accuracy: 0.5541 - val_loss: 1.0166\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.5582 - val_accuracy: 0.5647 - val_loss: 1.0168\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4952 - val_accuracy: 0.6035 - val_loss: 0.9391\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.4155 - val_accuracy: 0.6598 - val_loss: 0.8079\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8422 - loss: 0.3916 - val_accuracy: 0.7086 - val_loss: 0.7326\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.3427 - val_accuracy: 0.7336 - val_loss: 0.6985\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3105 - val_accuracy: 0.7523 - val_loss: 0.6271\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2766 - val_accuracy: 0.7473 - val_loss: 0.6895\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.2861 - val_accuracy: 0.8018 - val_loss: 0.5143\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.2405 - val_accuracy: 0.8224 - val_loss: 0.4403\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9085 - loss: 0.2283 - val_accuracy: 0.8424 - val_loss: 0.4416\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2277 - val_accuracy: 0.8530 - val_loss: 0.3997\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2003 - val_accuracy: 0.8762 - val_loss: 0.3523\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.1977 - val_accuracy: 0.8724 - val_loss: 0.3786\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.1933 - val_accuracy: 0.8668 - val_loss: 0.3601\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.1815 - val_accuracy: 0.8043 - val_loss: 0.6207\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 15: 90.71%\n",
            "\n",
            "--- FOLD 16/28 | TESTING on Subject 16 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3026 - loss: 1.6888 - val_accuracy: 0.3371 - val_loss: 1.3463\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4710 - loss: 1.1409 - val_accuracy: 0.3502 - val_loss: 1.3400\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5901 - loss: 0.9309 - val_accuracy: 0.4059 - val_loss: 1.2706\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6675 - loss: 0.7758 - val_accuracy: 0.4897 - val_loss: 1.1231\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.6475 - val_accuracy: 0.5591 - val_loss: 1.0518\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5383 - val_accuracy: 0.5954 - val_loss: 0.9734\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4720 - val_accuracy: 0.6229 - val_loss: 0.9063\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.4167 - val_accuracy: 0.6341 - val_loss: 0.8818\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.3785 - val_accuracy: 0.7054 - val_loss: 0.7143\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8714 - loss: 0.3264 - val_accuracy: 0.7580 - val_loss: 0.6130\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.3016 - val_accuracy: 0.7767 - val_loss: 0.6179\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3131 - val_accuracy: 0.7849 - val_loss: 0.5742\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2534 - val_accuracy: 0.7792 - val_loss: 0.5789\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2508 - val_accuracy: 0.8249 - val_loss: 0.4740\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2264 - val_accuracy: 0.8143 - val_loss: 0.5001\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2289 - val_accuracy: 0.8674 - val_loss: 0.3700\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9207 - loss: 0.2140 - val_accuracy: 0.8749 - val_loss: 0.3909\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2052 - val_accuracy: 0.8881 - val_loss: 0.3297\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.1786 - val_accuracy: 0.8555 - val_loss: 0.4076\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.1825 - val_accuracy: 0.9174 - val_loss: 0.2539\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 16: 94.76%\n",
            "\n",
            "--- FOLD 17/28 | TESTING on Subject 17 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3087 - loss: 1.6455 - val_accuracy: 0.3659 - val_loss: 1.3255\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4921 - loss: 1.1169 - val_accuracy: 0.3846 - val_loss: 1.2953\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 0.9075 - val_accuracy: 0.4753 - val_loss: 1.1403\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.7703 - val_accuracy: 0.4909 - val_loss: 1.1562\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.6577 - val_accuracy: 0.5879 - val_loss: 0.9678\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.5680 - val_accuracy: 0.5716 - val_loss: 0.9940\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.5061 - val_accuracy: 0.6610 - val_loss: 0.8121\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4210 - val_accuracy: 0.6917 - val_loss: 0.7512\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3964 - val_accuracy: 0.7242 - val_loss: 0.7063\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3487 - val_accuracy: 0.7223 - val_loss: 0.7128\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.3060 - val_accuracy: 0.7811 - val_loss: 0.5718\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2970 - val_accuracy: 0.7280 - val_loss: 0.6986\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2616 - val_accuracy: 0.8068 - val_loss: 0.5063\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.2612 - val_accuracy: 0.8124 - val_loss: 0.5020\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.2354 - val_accuracy: 0.8493 - val_loss: 0.3924\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2175 - val_accuracy: 0.8649 - val_loss: 0.4034\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2109 - val_accuracy: 0.8593 - val_loss: 0.3678\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2171 - val_accuracy: 0.8843 - val_loss: 0.3229\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.1898 - val_accuracy: 0.8849 - val_loss: 0.3224\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.1777 - val_accuracy: 0.8343 - val_loss: 0.4549\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 17: 96.62%\n",
            "\n",
            "--- FOLD 18/28 | TESTING on Subject 18 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3291 - loss: 1.6380 - val_accuracy: 0.3602 - val_loss: 1.3076\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5009 - loss: 1.0879 - val_accuracy: 0.3865 - val_loss: 1.2800\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6118 - loss: 0.8838 - val_accuracy: 0.4534 - val_loss: 1.2039\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6897 - loss: 0.7365 - val_accuracy: 0.5022 - val_loss: 1.0732\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.6260 - val_accuracy: 0.5772 - val_loss: 1.0103\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.5287 - val_accuracy: 0.6085 - val_loss: 0.9905\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4828 - val_accuracy: 0.6954 - val_loss: 0.7830\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.4027 - val_accuracy: 0.6767 - val_loss: 0.8121\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.3594 - val_accuracy: 0.7117 - val_loss: 0.7163\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.3207 - val_accuracy: 0.7680 - val_loss: 0.6470\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8816 - loss: 0.2955 - val_accuracy: 0.8168 - val_loss: 0.5173\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.2549 - val_accuracy: 0.8330 - val_loss: 0.4947\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.2511 - val_accuracy: 0.8487 - val_loss: 0.4398\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2493 - val_accuracy: 0.8093 - val_loss: 0.5261\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2588 - val_accuracy: 0.8655 - val_loss: 0.3864\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2160 - val_accuracy: 0.8424 - val_loss: 0.4317\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.1984 - val_accuracy: 0.8906 - val_loss: 0.3451\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.1836 - val_accuracy: 0.8906 - val_loss: 0.3248\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.1689 - val_accuracy: 0.8856 - val_loss: 0.3411\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.1788 - val_accuracy: 0.8856 - val_loss: 0.3686\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "Accuracy on Subject 18: 88.51%\n",
            "\n",
            "--- FOLD 19/28 | TESTING on Subject 19 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3200 - loss: 1.6428 - val_accuracy: 0.3515 - val_loss: 1.3005\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5098 - loss: 1.0677 - val_accuracy: 0.3877 - val_loss: 1.2595\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 0.8787 - val_accuracy: 0.4365 - val_loss: 1.1895\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 0.7532 - val_accuracy: 0.4853 - val_loss: 1.2288\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.6422 - val_accuracy: 0.5604 - val_loss: 1.0136\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.5522 - val_accuracy: 0.5947 - val_loss: 0.9589\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4871 - val_accuracy: 0.6498 - val_loss: 0.8421\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.4277 - val_accuracy: 0.6986 - val_loss: 0.7648\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3829 - val_accuracy: 0.7236 - val_loss: 0.6932\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3243 - val_accuracy: 0.7598 - val_loss: 0.6084\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.3371 - val_accuracy: 0.8086 - val_loss: 0.5307\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.2805 - val_accuracy: 0.7699 - val_loss: 0.5901\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9009 - loss: 0.2731 - val_accuracy: 0.8243 - val_loss: 0.4736\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2525 - val_accuracy: 0.8449 - val_loss: 0.4377\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2215 - val_accuracy: 0.8049 - val_loss: 0.5212\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2285 - val_accuracy: 0.8355 - val_loss: 0.4544\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2148 - val_accuracy: 0.8912 - val_loss: 0.3228\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1864 - val_accuracy: 0.8743 - val_loss: 0.3563\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.1862 - val_accuracy: 0.8737 - val_loss: 0.3942\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.1700 - val_accuracy: 0.9018 - val_loss: 0.3066\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "Accuracy on Subject 19: 94.59%\n",
            "\n",
            "--- FOLD 20/28 | TESTING on Subject 20 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3005 - loss: 1.7377 - val_accuracy: 0.3502 - val_loss: 1.3283\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4430 - loss: 1.1870 - val_accuracy: 0.3609 - val_loss: 1.3004\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5751 - loss: 0.9496 - val_accuracy: 0.4415 - val_loss: 1.2247\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.7970 - val_accuracy: 0.4440 - val_loss: 1.2598\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.7169 - val_accuracy: 0.4909 - val_loss: 1.1421\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6250 - val_accuracy: 0.5410 - val_loss: 1.0847\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7750 - loss: 0.5475 - val_accuracy: 0.6154 - val_loss: 0.9241\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.4563 - val_accuracy: 0.6492 - val_loss: 0.8732\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.4265 - val_accuracy: 0.6848 - val_loss: 0.8045\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.3686 - val_accuracy: 0.7242 - val_loss: 0.7016\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3456 - val_accuracy: 0.7755 - val_loss: 0.5775\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.3028 - val_accuracy: 0.7761 - val_loss: 0.5953\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.2955 - val_accuracy: 0.7830 - val_loss: 0.5317\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8831 - loss: 0.2919 - val_accuracy: 0.8280 - val_loss: 0.4913\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9030 - loss: 0.2457 - val_accuracy: 0.8361 - val_loss: 0.4592\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2342 - val_accuracy: 0.8393 - val_loss: 0.4369\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2268 - val_accuracy: 0.8862 - val_loss: 0.3314\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.2097 - val_accuracy: 0.8712 - val_loss: 0.4012\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2128 - val_accuracy: 0.8893 - val_loss: 0.3357\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2066 - val_accuracy: 0.8124 - val_loss: 0.5174\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Accuracy on Subject 20: 93.41%\n",
            "\n",
            "--- FOLD 21/28 | TESTING on Subject 21 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3321 - loss: 1.5913 - val_accuracy: 0.3046 - val_loss: 1.3412\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5117 - loss: 1.0617 - val_accuracy: 0.4271 - val_loss: 1.2199\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6079 - loss: 0.8890 - val_accuracy: 0.4522 - val_loss: 1.1869\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.7555 - val_accuracy: 0.5153 - val_loss: 1.0625\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.6430 - val_accuracy: 0.5228 - val_loss: 1.1532\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.5596 - val_accuracy: 0.5916 - val_loss: 1.0046\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4778 - val_accuracy: 0.6335 - val_loss: 0.9142\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4325 - val_accuracy: 0.7217 - val_loss: 0.7273\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3802 - val_accuracy: 0.7311 - val_loss: 0.6993\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 0.3456 - val_accuracy: 0.7261 - val_loss: 0.6765\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.3251 - val_accuracy: 0.8036 - val_loss: 0.5519\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.2989 - val_accuracy: 0.8161 - val_loss: 0.5043\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.2856 - val_accuracy: 0.8118 - val_loss: 0.5131\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2718 - val_accuracy: 0.7999 - val_loss: 0.5009\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.2592 - val_accuracy: 0.7855 - val_loss: 0.5645\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2384 - val_accuracy: 0.8787 - val_loss: 0.3468\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.2356 - val_accuracy: 0.8862 - val_loss: 0.3244\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2028 - val_accuracy: 0.8612 - val_loss: 0.4097\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.1886 - val_accuracy: 0.8643 - val_loss: 0.4400\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.1865 - val_accuracy: 0.9275 - val_loss: 0.2525\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
            "Accuracy on Subject 21: 96.79%\n",
            "\n",
            "--- FOLD 22/28 | TESTING on Subject 22 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3205 - loss: 1.6634 - val_accuracy: 0.3427 - val_loss: 1.3196\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5063 - loss: 1.0776 - val_accuracy: 0.4021 - val_loss: 1.2463\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6054 - loss: 0.8988 - val_accuracy: 0.4490 - val_loss: 1.2138\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6764 - loss: 0.7560 - val_accuracy: 0.4778 - val_loss: 1.1555\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.6555 - val_accuracy: 0.5466 - val_loss: 1.0323\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.5593 - val_accuracy: 0.5841 - val_loss: 0.9574\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.5101 - val_accuracy: 0.6110 - val_loss: 0.9486\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.4611 - val_accuracy: 0.6760 - val_loss: 0.8031\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4040 - val_accuracy: 0.7117 - val_loss: 0.7523\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3711 - val_accuracy: 0.7467 - val_loss: 0.6412\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8791 - loss: 0.3097 - val_accuracy: 0.7655 - val_loss: 0.6122\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.2884 - val_accuracy: 0.7755 - val_loss: 0.6109\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2888 - val_accuracy: 0.7930 - val_loss: 0.5576\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2711 - val_accuracy: 0.7992 - val_loss: 0.4967\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2306 - val_accuracy: 0.8505 - val_loss: 0.4094\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.2429 - val_accuracy: 0.8424 - val_loss: 0.4758\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2157 - val_accuracy: 0.8405 - val_loss: 0.4281\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2047 - val_accuracy: 0.8968 - val_loss: 0.3150\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1823 - val_accuracy: 0.8881 - val_loss: 0.3023\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2081 - val_accuracy: 0.8893 - val_loss: 0.3146\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 22: 92.74%\n",
            "\n",
            "--- FOLD 23/28 | TESTING on Subject 23 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3430 - loss: 1.7487 - val_accuracy: 0.3427 - val_loss: 1.3353\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5063 - loss: 1.0563 - val_accuracy: 0.3740 - val_loss: 1.3261\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 0.8880 - val_accuracy: 0.4422 - val_loss: 1.2653\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6789 - loss: 0.7566 - val_accuracy: 0.4740 - val_loss: 1.1985\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.6720 - val_accuracy: 0.5572 - val_loss: 1.0557\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7682 - loss: 0.5508 - val_accuracy: 0.5747 - val_loss: 0.9861\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5096 - val_accuracy: 0.6141 - val_loss: 0.9394\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4539 - val_accuracy: 0.6523 - val_loss: 0.8434\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8447 - loss: 0.3866 - val_accuracy: 0.7498 - val_loss: 0.6775\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.3698 - val_accuracy: 0.7348 - val_loss: 0.6803\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8639 - loss: 0.3360 - val_accuracy: 0.7573 - val_loss: 0.6417\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.2965 - val_accuracy: 0.7792 - val_loss: 0.5552\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2668 - val_accuracy: 0.8230 - val_loss: 0.4910\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2684 - val_accuracy: 0.8105 - val_loss: 0.4797\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2492 - val_accuracy: 0.8318 - val_loss: 0.4661\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.2377 - val_accuracy: 0.8624 - val_loss: 0.4008\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2136 - val_accuracy: 0.8293 - val_loss: 0.4529\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2321 - val_accuracy: 0.8762 - val_loss: 0.3531\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.1995 - val_accuracy: 0.8868 - val_loss: 0.3021\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.1693 - val_accuracy: 0.8993 - val_loss: 0.3045\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 23: 86.15%\n",
            "\n",
            "--- FOLD 24/28 | TESTING on Subject 24 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3166 - loss: 1.7393 - val_accuracy: 0.3440 - val_loss: 1.3542\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 1.0812 - val_accuracy: 0.3696 - val_loss: 1.3257\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5967 - loss: 0.9010 - val_accuracy: 0.4053 - val_loss: 1.2603\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 0.7492 - val_accuracy: 0.4271 - val_loss: 1.2108\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7085 - loss: 0.6827 - val_accuracy: 0.4916 - val_loss: 1.1334\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.6025 - val_accuracy: 0.5453 - val_loss: 1.0637\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.5170 - val_accuracy: 0.5854 - val_loss: 0.9782\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4762 - val_accuracy: 0.6479 - val_loss: 0.8662\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.4110 - val_accuracy: 0.6523 - val_loss: 0.8434\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.3738 - val_accuracy: 0.6698 - val_loss: 0.7978\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3512 - val_accuracy: 0.7098 - val_loss: 0.7216\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3155 - val_accuracy: 0.7336 - val_loss: 0.7028\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.3013 - val_accuracy: 0.8074 - val_loss: 0.5371\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.2768 - val_accuracy: 0.7955 - val_loss: 0.5193\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.2599 - val_accuracy: 0.8143 - val_loss: 0.5307\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.2600 - val_accuracy: 0.8174 - val_loss: 0.5204\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.2535 - val_accuracy: 0.8355 - val_loss: 0.4612\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.2291 - val_accuracy: 0.7786 - val_loss: 0.5989\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2046 - val_accuracy: 0.8318 - val_loss: 0.5074\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2075 - val_accuracy: 0.8468 - val_loss: 0.4358\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
            "Accuracy on Subject 24: 94.93%\n",
            "\n",
            "--- FOLD 25/28 | TESTING on Subject 25 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3124 - loss: 1.7655 - val_accuracy: 0.3333 - val_loss: 1.3745\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5184 - loss: 1.0612 - val_accuracy: 0.3652 - val_loss: 1.3374\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 0.8809 - val_accuracy: 0.3702 - val_loss: 1.2899\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.7682 - val_accuracy: 0.4065 - val_loss: 1.2640\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7209 - loss: 0.6695 - val_accuracy: 0.4847 - val_loss: 1.1771\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.5793 - val_accuracy: 0.5253 - val_loss: 1.1221\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.5089 - val_accuracy: 0.5679 - val_loss: 0.9974\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.4614 - val_accuracy: 0.6310 - val_loss: 0.8576\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.4125 - val_accuracy: 0.6235 - val_loss: 0.8945\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.3605 - val_accuracy: 0.6560 - val_loss: 0.8362\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8723 - loss: 0.3245 - val_accuracy: 0.7192 - val_loss: 0.6887\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.3008 - val_accuracy: 0.7355 - val_loss: 0.6718\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2890 - val_accuracy: 0.7674 - val_loss: 0.6011\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.2744 - val_accuracy: 0.8418 - val_loss: 0.4364\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.2473 - val_accuracy: 0.7655 - val_loss: 0.6570\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2260 - val_accuracy: 0.8530 - val_loss: 0.3923\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2142 - val_accuracy: 0.8749 - val_loss: 0.3787\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.2151 - val_accuracy: 0.8405 - val_loss: 0.4234\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.1950 - val_accuracy: 0.9181 - val_loss: 0.2623\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.1838 - val_accuracy: 0.8943 - val_loss: 0.3211\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "Accuracy on Subject 25: 94.26%\n",
            "\n",
            "--- FOLD 26/28 | TESTING on Subject 26 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3139 - loss: 1.6691 - val_accuracy: 0.3240 - val_loss: 1.3384\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 1.0880 - val_accuracy: 0.3909 - val_loss: 1.2939\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 0.8996 - val_accuracy: 0.4353 - val_loss: 1.2258\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.7418 - val_accuracy: 0.4628 - val_loss: 1.1663\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.6553 - val_accuracy: 0.4790 - val_loss: 1.1841\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.5540 - val_accuracy: 0.5666 - val_loss: 1.0104\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.4934 - val_accuracy: 0.5791 - val_loss: 0.9483\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4576 - val_accuracy: 0.6260 - val_loss: 0.8736\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3762 - val_accuracy: 0.6898 - val_loss: 0.7479\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3885 - val_accuracy: 0.7211 - val_loss: 0.6601\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3224 - val_accuracy: 0.7667 - val_loss: 0.5818\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.2986 - val_accuracy: 0.7974 - val_loss: 0.5345\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.2746 - val_accuracy: 0.7573 - val_loss: 0.6247\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9015 - loss: 0.2559 - val_accuracy: 0.8080 - val_loss: 0.4858\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2371 - val_accuracy: 0.8286 - val_loss: 0.4459\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2366 - val_accuracy: 0.8374 - val_loss: 0.4417\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2420 - val_accuracy: 0.8374 - val_loss: 0.4552\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2358 - val_accuracy: 0.8787 - val_loss: 0.3368\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2012 - val_accuracy: 0.8718 - val_loss: 0.3558\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.1907 - val_accuracy: 0.8674 - val_loss: 0.3747\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 26: 90.88%\n",
            "\n",
            "--- FOLD 27/28 | TESTING on Subject 27 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3394 - loss: 1.6187 - val_accuracy: 0.3377 - val_loss: 1.3557\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5365 - loss: 1.0290 - val_accuracy: 0.3515 - val_loss: 1.3030\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.8298 - val_accuracy: 0.4422 - val_loss: 1.2225\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.7131 - val_accuracy: 0.4897 - val_loss: 1.1487\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 0.6340 - val_accuracy: 0.5203 - val_loss: 1.0675\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.5695 - val_accuracy: 0.5553 - val_loss: 1.0245\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.5088 - val_accuracy: 0.6004 - val_loss: 0.9565\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.4361 - val_accuracy: 0.6098 - val_loss: 0.9504\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.4070 - val_accuracy: 0.6729 - val_loss: 0.8297\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3524 - val_accuracy: 0.7373 - val_loss: 0.6784\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3211 - val_accuracy: 0.7642 - val_loss: 0.6254\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.3125 - val_accuracy: 0.7917 - val_loss: 0.5894\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8940 - loss: 0.2663 - val_accuracy: 0.7711 - val_loss: 0.6287\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2664 - val_accuracy: 0.8361 - val_loss: 0.4581\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.2496 - val_accuracy: 0.8243 - val_loss: 0.4527\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2311 - val_accuracy: 0.8730 - val_loss: 0.3877\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 0.2023 - val_accuracy: 0.8793 - val_loss: 0.3505\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2116 - val_accuracy: 0.8587 - val_loss: 0.4020\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.1890 - val_accuracy: 0.8768 - val_loss: 0.3462\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.1853 - val_accuracy: 0.8518 - val_loss: 0.4208\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 27: 89.86%\n",
            "\n",
            "--- FOLD 28/28 | TESTING on Subject 28 ---\n",
            "Data normalized. Train shape: (15984, 384, 14), Test shape: (592, 384, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.3245 - loss: 1.6674 - val_accuracy: 0.3321 - val_loss: 1.3623\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5182 - loss: 1.0659 - val_accuracy: 0.3896 - val_loss: 1.2686\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6082 - loss: 0.8665 - val_accuracy: 0.4897 - val_loss: 1.1592\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.7420 - val_accuracy: 0.5560 - val_loss: 1.0464\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7297 - loss: 0.6382 - val_accuracy: 0.5829 - val_loss: 1.0022\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7623 - loss: 0.5800 - val_accuracy: 0.6329 - val_loss: 0.8781\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.5008 - val_accuracy: 0.6879 - val_loss: 0.8083\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4599 - val_accuracy: 0.7611 - val_loss: 0.6259\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.4065 - val_accuracy: 0.7892 - val_loss: 0.5510\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3603 - val_accuracy: 0.7517 - val_loss: 0.6766\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.3282 - val_accuracy: 0.8261 - val_loss: 0.4702\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.3163 - val_accuracy: 0.8236 - val_loss: 0.4776\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.2857 - val_accuracy: 0.7899 - val_loss: 0.5976\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.2772 - val_accuracy: 0.8824 - val_loss: 0.3488\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2858 - val_accuracy: 0.8568 - val_loss: 0.3906\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.2356 - val_accuracy: 0.8774 - val_loss: 0.3506\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2247 - val_accuracy: 0.9181 - val_loss: 0.2621\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.2081 - val_accuracy: 0.9006 - val_loss: 0.2952\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.1944 - val_accuracy: 0.9181 - val_loss: 0.2671\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.2012 - val_accuracy: 0.9168 - val_loss: 0.2590\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Accuracy on Subject 28: 83.78%\n",
            "\n",
            "--- Total DL Training Time: 25.02 minutes ---\n",
            "\n",
            "\n",
            "Model Accuracy (Mean): 86.56%\n",
            "Model Accuracy (Std Dev): 19.12%\n",
            "\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Boring       0.85      0.90      0.87      4144\n",
            "        Calm       0.86      0.83      0.84      4144\n",
            "      Horror       0.89      0.86      0.87      4144\n",
            "       Funny       0.87      0.87      0.87      4144\n",
            "\n",
            "    accuracy                           0.87     16576\n",
            "   macro avg       0.87      0.87      0.87     16576\n",
            "weighted avg       0.87      0.87      0.87     16576\n",
            "\n",
            "\n",
            "Overall Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fXrG67la_2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}